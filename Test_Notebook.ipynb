{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling mit Python I\n",
    "\n",
    "## Einf√ºhrung\n",
    "\n",
    "Die Programmiersprache Python hat in den letzten Jahren unglaublich an Beliebtheit gewonnen. Besondes im Bereich Maschinelles Lernen und"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In diesem Jupyter-Notebook werden grundlegende "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using the Jupyter-Notebook:\n",
    "\n",
    "### [Keyboard Shortcuts](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Custom%20Keyboard%20Shortcuts.html)\n",
    "\n",
    "| Command | Action |\n",
    "| --- | --- |\n",
    "|Ctrl + Enter | run selected cells |\n",
    "|Alt + Enter | run the current cell, insert below |\n",
    "|Shift + Enter | run the current cell, select below |\n",
    "|Ctrl + S | save and checkpoint |\n",
    "\n",
    "### [Magic-Commands and othes](https://ipython.readthedocs.io/en/stable/interactive/magics.html)\n",
    "\n",
    "| Command | Action |\n",
    "| --- | --- |\n",
    "| %load python_file.py| load code from python_file.py into Cell |\n",
    "| %run python_file.py| run python_file.py |\n",
    "| %time | times how long a cell needs to finish |\n",
    "| %ls | shows file in the current directory |\n",
    "| %pwd | shows path of the current directory |\n",
    "\n",
    "Want more? Here are [28 Tips, Tricks and Shortcuts](https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the packages we need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Show visualisation inside the notebook (not needed anymore in newer versions)\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataframe from CSV\n",
    "# use utf-8\n",
    "df_price = pd.read_csv(\"./FlourishOA_Data/api_price11-13-17.csv\",  encoding=\"ISO-8859-1\", sep=',', decimal='.')\n",
    "# we can read json, excel, sql, and more ... https://pandas.pydata.org/pandas-docs/stable/reference/io.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first lines of dataset\n",
    "df_price.head()\n",
    "# df.tail() for last lines and df for (reduced) view of the whole Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basic information about datatypes, entries and columns\n",
    "df_price.info()\n",
    "# more infos about datatypes in pandas: https://pbpython.com/pandas_dtypes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets change this!\n",
    "df_price[\"date_stamp\"] = pd.to_datetime(df_price['date_stamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a look again\n",
    "df_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is column `id` really a unique identifier?\n",
    "unique_id = df_price[\"id\"].nunique()\n",
    "count_id = df_price[\"id\"].count()\n",
    "ununique_count = count_id - unique_id\n",
    "ununique_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the journal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataframe from CSV\n",
    "df_journal = pd.read_csv(\"./FlourishOA_Data/api_journal11-13-17.csv\",  encoding=\"ISO-8859-1\", sep=',', decimal='.')\n",
    "# we can read json, excel, sql, and more ... https://pandas.pydata.org/pandas-docs/stable/reference/io.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 lines of dataset\n",
    "df_journal.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basic information about datatypes, entries and columns\n",
    "df_journal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there only 0 and 1 in `is_hybrid`?\n",
    "df_journal.groupby(\"is_hybrid\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data-type for is_hybrid\n",
    "df_journal[\"is_hybrid\"] = df_journal[\"is_hybrid\"].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a look again\n",
    "df_journal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the different categories\n",
    "df_journal.groupby(\"category\", sort=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all categorys to uppercase\n",
    "category_series = df_journal[\"category\"]\n",
    "df_journal[\"category\"] = df_journal[\"category\"].map(lambda x: x if x is np.nan else x.upper() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the different categories again\n",
    "df_journal.groupby(\"category\", sort=True).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a look at one specific category \"AGRICULTURE\" \n",
    "category_series_filter = df_journal[df_journal[\"category\"].notnull()][\"category\"].map(lambda x: \"AGRICULTURE\" in x)\n",
    "category_series_filter\n",
    "df_journal[df_journal[\"category\"].notnull()][category_series_filter]\n",
    "df_journal[df_journal[\"category\"].notnull()][category_series_filter].groupby(\"category\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different seperator in mulitcategories. Lets find them\n",
    "category_series_filter = df_journal[df_journal[\"category\"].notnull()][\"category\"].map(lambda x: \".\" in x)\n",
    "df_journal[df_journal[\"category\"].notnull()][category_series_filter]\n",
    "df_journal[df_journal[\"category\"].notnull()][category_series_filter].groupby(\"category\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \".\" with \" |\"\n",
    "df_journal[\"category\"] = df_journal[\"category\"].map(lambda x: x if x is np.nan else x.replace(\".\", \" |\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at Results with specific category \"PHILOSOPHY\"\n",
    "category_series_filter = df_journal[df_journal[\"category\"].notnull()][\"category\"].str.contains(\"PHILOSOPHY\") #df[df[\"category\"].notnull()][\"category\"].str.contains()\n",
    "\n",
    "df_journal[df_journal[\"category\"].notnull()][category_series_filter]\n",
    "df_journal[df_journal[\"category\"].notnull()][category_series_filter].groupby(\"category\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get a list of all Categories\n",
    "\n",
    "# 1. split categories\n",
    "def category_string_to_list(category_string):\n",
    "    category_list = [x.strip() for x in str(category_string).split('|')]\n",
    "    return category_list\n",
    "\n",
    "category_list_series = df_journal[\"category\"].map(category_string_to_list)\n",
    "category_list_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. creating a set of all categorys ant get it length\n",
    "category_set = set()\n",
    "\n",
    "category_lists = category_list_series.tolist()\n",
    "for category_list in category_lists:\n",
    "    category_set.update(category_list)\n",
    "\n",
    "print(category_set)\n",
    "len(category_set)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge journal and price Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Number of ununique columns for possible merge\n",
    "def get_ununique_count(df, column):\n",
    "    return df[column].count() - df[column].nunique()\n",
    "\n",
    "print(df_price.columns)\n",
    "for column in df_price.columns:\n",
    "    print(column, get_ununique_count(df_price, column))\n",
    "\n",
    "print(df_journal.columns)\n",
    "for column in df_journal.columns:\n",
    "    print(column)\n",
    "    print(get_ununique_count(df_journal, column))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging two dataframes\n",
    "\n",
    "df_merge = pd.merge(df_journal, df_price, how='inner', left_on='issn', right_on='journal_id',\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)[[\"journal_name\", \"price\", \"category\", \"influence_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a look at the merged data\n",
    "print(df_merge.info())\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get generall informations about the price of articles\n",
    "df_merge.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a lineplot\n",
    "df_merge.price.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histogramm with 16 bins\n",
    "df_merge.price.plot.hist(bins=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all articles with price 0\n",
    "df_merge[df_merge.price == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grouped information about journals\n",
    "table = pd.pivot_table(df_merge, values=[\"price\"], index=\"journal_name\", aggfunc={'price': [min, max ,np.sum, len, np.mean]})\n",
    "table.sort_values(by=(\"price\", \"sum\"), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export table to excel-format\n",
    "table.to_excel(\"././FlourishOA_Data/journal-price_pivot-table.xlsx\")\n",
    "# want more possibilities to work with excel? https://pbpython.com/improve-pandas-excel-output.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}